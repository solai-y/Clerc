import requests
import json
import time
import threading
from typing import List, Dict, Any

BASE_URL = "http://localhost:5002"

class TestTagOperationsE2E:
    """End-to-end tests for tag operations via HTTP requests"""
    
    def setup_method(self):
        """Setup for each test method"""
        self.base_url = BASE_URL
        self.created_documents = []
    
    def teardown_method(self):
        """Cleanup after each test method"""
        # Clean up any documents created during testing
        for doc_id in self.created_documents:
            try:
                requests.delete(f"{self.base_url}/documents/{doc_id}")
            except:
                pass  # Ignore cleanup errors
    
    def create_test_document_with_processing(self, name_suffix: str = "") -> Dict[str, Any]:
        """Helper method to create a document with processed entry"""
        # Create raw document
        raw_doc_data = {
            "document_name": f"E2E Tag Test Document {name_suffix}",
            "document_type": "PDF",
            "link": f"https://test.com/e2e-tag-test-{name_suffix}.pdf",
            "uploaded_by": 6,
        }
        
        raw_response = requests.post(
            f"{self.base_url}/documents",
            json=raw_doc_data,
            headers={'Content-Type': 'application/json'}
        )
        
        assert raw_response.status_code == 201
        document_id = raw_response.json()["data"]["document_id"]
        self.created_documents.append(document_id)
        
        # Create processed document entry
        processed_data = {
            "document_id": document_id,
            "threshold_pct": 80,
            "suggested_tags": [
                {"tag": "invoice", "score": 0.95},
                {"tag": "financial", "score": 0.87},
                {"tag": "quarterly", "score": 0.72},
                {"tag": "urgent", "score": 0.68}
            ],
            "ocr_used": True,
            "processing_ms": 1500
        }
        
        processed_response = requests.post(
            f"{self.base_url}/documents/processed",
            json=processed_data,
            headers={'Content-Type': 'application/json'}
        )
        
        assert processed_response.status_code == 201
        
        return {
            "document_id": document_id,
            "raw_data": raw_doc_data,
            "processed_data": processed_data
        }
    
    def test_tag_update_endpoint_availability(self):
        """Test that the tag update endpoint is available"""
        print("\n[TEST] Testing tag update endpoint availability...")
        
        # First check if the service has the tag endpoints
        root_response = requests.get(f"{self.base_url}/")
        if root_response.status_code == 200:
            root_data = root_response.json()
            endpoints = root_data.get("data", {}).get("endpoints", [])
            tag_endpoint_exists = any("tags" in endpoint for endpoint in endpoints)
            
            if not tag_endpoint_exists:
                print("‚ö†Ô∏è  [SKIP] Tag update endpoints not available in running service")
                print("   The service needs to be restarted to pick up the new tag functionality")
                print("   Please restart the service: cd ../.. && python app.py")
                return
        
        # Create test document
        doc_info = self.create_test_document_with_processing("availability")
        document_id = doc_info["document_id"]
        
        # Test the endpoint exists and responds correctly
        tag_data = {
            "confirmed_tags": ["invoice"]
        }
        
        response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            json=tag_data,
            headers={'Content-Type': 'application/json'}
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "success"
        assert data["message"] == "Document tags updated successfully"
        
        print("[PASS] Tag update endpoint is available and responding correctly")
    
    def test_full_tag_management_workflow(self):
        """Test complete tag management workflow from frontend perspective"""
        print("\n[TEST] Testing full tag management workflow...")
        
        # Step 1: Create document with AI suggestions
        print("  [STEP 1] Creating document with AI tag suggestions...")
        doc_info = self.create_test_document_with_processing("workflow")
        document_id = doc_info["document_id"]
        
        # Step 2: Retrieve document to see AI suggestions from processed documents
        print("  [STEP 2] Retrieving document to view AI suggestions...")
        # Query processed documents, filtering by document_id
        get_response = requests.get(f"{self.base_url}/documents")
        assert get_response.status_code == 200
        
        # Find our created document in the processed documents
        documents = get_response.json()["data"]["documents"]
        doc_data = None
        for doc in documents:
            if doc["document_id"] == document_id:
                doc_data = doc
                break
        
        assert doc_data is not None, f"Document {document_id} not found in processed documents"
        
        # Verify AI suggestions are present
        assert len(doc_data["suggested_tags"]) == 4
        ai_tags = [tag["tag"] for tag in doc_data["suggested_tags"]]
        assert "invoice" in ai_tags
        assert "financial" in ai_tags
        
        print("  [PASS] AI tag suggestions retrieved successfully")
        
        # Step 3: User confirms some AI tags and adds custom tags (simulating modal interaction)
        print("  [STEP 3] User confirming AI tags and adding custom tags...")
        tag_update_data = {
            "confirmed_tags": ["invoice", "financial"],  # Confirmed AI tags
            "user_added_labels": ["client-abc", "priority-high", "q1-2024"]  # Custom tags
        }
        
        update_response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            json=tag_update_data,
            headers={'Content-Type': 'application/json'}
        )
        
        assert update_response.status_code == 200
        update_data = update_response.json()
        assert update_data["status"] == "success"

        # Check new JSONB structure for confirmed_tags
        confirmed_tags = update_data["data"]["confirmed_tags"]
        assert "tags" in confirmed_tags
        tag_names = [tag["tag"] for tag in confirmed_tags["tags"]]
        assert set(tag_names) == {"invoice", "financial"}
        assert update_data["data"]["user_added_labels"] == ["client-abc", "priority-high", "q1-2024"]
        
        print("  [PASS] Tags confirmed and custom tags added successfully")
        
        # Step 4: User modifies tags (removing some, adding others)
        print("  [STEP 4] User modifying existing tags...")
        modified_tag_data = {
            "confirmed_tags": ["invoice"],  # Removed "financial"
            "user_added_labels": ["client-abc", "priority-medium", "q1-2024", "reviewed"]  # Modified priority, added reviewed
        }
        
        modify_response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            json=modified_tag_data,
            headers={'Content-Type': 'application/json'}
        )
        
        assert modify_response.status_code == 200
        modify_data = modify_response.json()

        # Check new JSONB structure for confirmed_tags
        confirmed_tags = modify_data["data"]["confirmed_tags"]
        assert "tags" in confirmed_tags
        tag_names = [tag["tag"] for tag in confirmed_tags["tags"]]
        assert tag_names == ["invoice"]
        assert set(modify_data["data"]["user_added_labels"]) == {"client-abc", "priority-medium", "q1-2024", "reviewed"}
        
        print("  [PASS] Tag modifications applied successfully")
        
        # Step 5: Final verification
        print("  [STEP 5] Final verification of tag state...")
        # Query processed documents again to verify final state
        final_response = requests.get(f"{self.base_url}/documents")
        assert final_response.status_code == 200
        
        # Find our document in processed documents
        final_documents = final_response.json()["data"]["documents"]
        final_doc = None
        for doc in final_documents:
            if doc["document_id"] == document_id:
                final_doc = doc
                break
        
        assert final_doc is not None, f"Document {document_id} not found in final verification"

        # Check new JSONB structure for confirmed_tags
        confirmed_tags = final_doc["confirmed_tags"]
        assert "tags" in confirmed_tags
        tag_names = [tag["tag"] for tag in confirmed_tags["tags"]]
        assert tag_names == ["invoice"]
        assert set(final_doc["user_added_labels"]) == {"client-abc", "priority-medium", "q1-2024", "reviewed"}
        # AI suggestions should still be preserved
        assert len(final_doc["suggested_tags"]) == 4
        
        print("  [PASS] Final tag state verified successfully")
        print("[SUCCESS] Full tag management workflow completed successfully")
    
    def test_concurrent_tag_operations(self):
        """Test concurrent tag operations on multiple documents"""
        print("\n[TEST] Testing concurrent tag operations...")
        
        # Create multiple documents
        documents = []
        for i in range(3):
            doc_info = self.create_test_document_with_processing(f"concurrent-{i}")
            documents.append(doc_info)
        
        results = []
        errors = []
        
        def update_document_tags(doc_info, tag_suffix):
            """Helper function for concurrent tag updates"""
            try:
                document_id = doc_info["document_id"]
                tag_data = {
                    "confirmed_tags": ["invoice"],
                    "user_added_labels": [f"concurrent-tag-{tag_suffix}", f"thread-{tag_suffix}"]
                }
                
                response = requests.patch(
                    f"{self.base_url}/documents/{document_id}/tags",
                    json=tag_data,
                    headers={'Content-Type': 'application/json'}
                )
                
                results.append({
                    "document_id": document_id,
                    "status_code": response.status_code,
                    "response_data": response.json()
                })
            except Exception as e:
                errors.append(f"Error updating document {doc_info['document_id']}: {str(e)}")
        
        # Start concurrent operations
        threads = []
        for i, doc_info in enumerate(documents):
            thread = threading.Thread(target=update_document_tags, args=(doc_info, i))
            threads.append(thread)
            thread.start()
        
        # Wait for all operations to complete
        for thread in threads:
            thread.join()
        
        # Verify results
        assert len(errors) == 0, f"Errors occurred: {errors}"
        assert len(results) == 3
        
        for result in results:
            assert result["status_code"] == 200
            assert result["response_data"]["status"] == "success"

            # Check new JSONB structure for confirmed_tags
            confirmed_tags = result["response_data"]["data"]["confirmed_tags"]
            assert "tags" in confirmed_tags
            tag_names = [tag["tag"] for tag in confirmed_tags["tags"]]
            assert tag_names == ["invoice"]
        
        print("  [PASS] All concurrent operations completed successfully")
        print("[SUCCESS] Concurrent tag operations test completed")
    
    def test_tag_operations_with_various_data_types(self):
        """Test tag operations with various edge cases and data types"""
        print("\n[TEST] Testing tag operations with various data types...")
        
        doc_info = self.create_test_document_with_processing("data-types")
        document_id = doc_info["document_id"]
        
        # Test 1: Empty arrays (clearing tags)
        print("  [TEST 1] Empty arrays (clearing tags)...")
        empty_data = {
            "confirmed_tags": [],
            "user_added_labels": []
        }
        
        response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            json=empty_data,
            headers={'Content-Type': 'application/json'}
        )
        
        assert response.status_code == 200

        # Check new JSONB structure for confirmed_tags (empty case)
        confirmed_tags = response.json()["data"]["confirmed_tags"]
        if confirmed_tags is None or confirmed_tags == {}:
            # Empty confirmed_tags
            pass
        else:
            assert "tags" in confirmed_tags
            assert confirmed_tags["tags"] == []
        assert response.json()["data"]["user_added_labels"] == []
        print("  [PASS] Empty arrays handled correctly")
        
        # Test 2: Special characters in tags
        print("  [TEST 2] Special characters in tags...")
        special_data = {
            "user_added_labels": [
                "tag-with-hyphens",
                "tag_with_underscores",
                "tag.with.dots",
                "tag with spaces",
                "tag@email.com",
                "tag#hashtag",
                "tag$money",
                "tag&ampersand",
                "tag(parentheses)",
                "tag[brackets]",
                "tag{braces}",
                "tag/forward/slash",
                "tag\\backslash",
                "tag|pipe",
                "tag:colon",
                "tag;semicolon",
                "tag'apostrophe",
                'tag"quote'
            ]
        }
        
        response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            json=special_data,
            headers={'Content-Type': 'application/json'}
        )
        
        assert response.status_code == 200
        result_tags = response.json()["data"]["user_added_labels"]
        assert len(result_tags) == len(special_data["user_added_labels"])
        print("  [PASS] Special characters in tags handled correctly")
        
        # Test 3: Very long tag names
        print("  [TEST 3] Long tag names...")
        long_tag = "a" * 100  # 100 character tag
        long_data = {
            "user_added_labels": [long_tag, "normal-tag"]
        }
        
        response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            json=long_data,
            headers={'Content-Type': 'application/json'}
        )
        
        assert response.status_code == 200
        assert long_tag in response.json()["data"]["user_added_labels"]
        print("  [PASS] Long tag names handled correctly")
        
        # Test 4: Unicode characters
        print("  [TEST 4] Unicode characters...")
        unicode_data = {
            "user_added_labels": [
                "tag-fran√ßais",
                "tag-espa√±ol",
                "tag-‰∏≠Êñá",
                "tag-ÿßŸÑÿπÿ±ÿ®Ÿäÿ©",
                "tag-—Ä—É—Å—Å–∫–∏–π",
                "tag-Êó•Êú¨Ë™û",
                "emoji-tag-üòÄ",
                "symbol-tag-¬©¬Æ‚Ñ¢"
            ]
        }
        
        response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            json=unicode_data,
            headers={'Content-Type': 'application/json'}
        )
        
        assert response.status_code == 200
        result_data = response.json()["data"]
        assert len(result_data["user_added_labels"]) == len(unicode_data["user_added_labels"])
        print("  [PASS] Unicode characters handled correctly")
        
        print("[SUCCESS] Various data types test completed")
    
    def test_tag_operations_error_scenarios(self):
        """Test error handling in tag operations"""
        print("\n[TEST] Testing tag operation error scenarios...")
        
        # Test 1: Non-existent document
        print("  [ERROR SCENARIO 1] Non-existent document...")
        response = requests.patch(
            f"{self.base_url}/documents/99999/tags",
            json={"confirmed_tags": ["test"]},
            headers={'Content-Type': 'application/json'}
        )
        
        assert response.status_code == 404
        assert response.json()["status"] == "error"
        print("  [PASS] 404 error for non-existent document")
        
        # Test 2: Invalid JSON
        print("  [ERROR SCENARIO 2] Invalid JSON...")
        doc_info = self.create_test_document_with_processing("error-test")
        document_id = doc_info["document_id"]
        
        response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            data="invalid json",
            headers={'Content-Type': 'application/json'}
        )
        
        assert response.status_code == 400
        print("  [PASS] 400 error for invalid JSON")
        
        # Test 3: Missing required fields
        print("  [ERROR SCENARIO 3] Missing required tag fields...")
        response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            json={"some_other_field": "value"},
            headers={'Content-Type': 'application/json'}
        )
        
        assert response.status_code == 400
        assert "at least one" in response.json()["message"].lower()
        print("  [PASS] 400 error for missing tag fields")
        
        # Test 4: Invalid data types
        print("  [ERROR SCENARIO 4] Invalid data types...")
        response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            json={
                "confirmed_tags": "not-an-array",
                "user_added_labels": 123
            },
            headers={'Content-Type': 'application/json'}
        )
        
        assert response.status_code == 400
        assert "must be an array" in response.json()["message"]
        print("  [PASS] 400 error for invalid data types")
        
        # Test 5: Empty request body
        print("  [ERROR SCENARIO 5] Empty request body...")
        response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            json={},
            headers={'Content-Type': 'application/json'}
        )
        
        assert response.status_code == 400
        print("  [PASS] 400 error for empty request body")
        
        print("[SUCCESS] All error scenarios handled correctly")
    
    def test_tag_operations_performance(self):
        """Test performance of tag operations with larger datasets"""
        print("\n[TEST] Testing tag operation performance...")
        
        doc_info = self.create_test_document_with_processing("performance")
        document_id = doc_info["document_id"]
        
        # Test with many tags
        print("  [PERFORMANCE TEST] Updating with many tags...")
        many_tags = [f"tag-{i}" for i in range(100)]  # 100 tags
        
        start_time = time.time()
        response = requests.patch(
            f"{self.base_url}/documents/{document_id}/tags",
            json={"user_added_labels": many_tags},
            headers={'Content-Type': 'application/json'}
        )
        end_time = time.time()
        
        assert response.status_code == 200
        assert len(response.json()["data"]["user_added_labels"]) == 100
        
        duration = end_time - start_time
        print(f"  [PERFORMANCE] Updated 100 tags in {duration:.2f} seconds")
        
        # Performance threshold (should complete in reasonable time)
        assert duration < 10.0, f"Tag update took too long: {duration:.2f} seconds"
        
        print("  [PASS] Performance test completed within acceptable time")
        print("[SUCCESS] Tag operation performance test completed")
    
    def test_tag_data_consistency_across_operations(self):
        """Test data consistency across multiple tag operations"""
        print("\n[TEST] Testing tag data consistency across operations...")
        
        doc_info = self.create_test_document_with_processing("consistency")
        document_id = doc_info["document_id"]
        
        operations = [
            {"confirmed_tags": ["invoice"], "user_added_labels": ["initial"]},
            {"confirmed_tags": ["invoice", "financial"], "user_added_labels": ["initial", "second"]},
            {"confirmed_tags": ["financial"], "user_added_labels": ["second", "third"]},
            {"confirmed_tags": ["financial", "quarterly"], "user_added_labels": ["third", "final"]}
        ]
        
        for i, operation in enumerate(operations):
            print(f"  [OPERATION {i+1}] Applying operation {i+1}...")
            
            # Apply operation
            response = requests.patch(
                f"{self.base_url}/documents/{document_id}/tags",
                json=operation,
                headers={'Content-Type': 'application/json'}
            )
            
            assert response.status_code == 200
            result = response.json()["data"]
            
            # Verify immediate consistency
            # Check new JSONB structure for confirmed_tags
            confirmed_tags = result["confirmed_tags"]
            assert "tags" in confirmed_tags
            result_tag_names = [tag["tag"] for tag in confirmed_tags["tags"]]
            assert set(result_tag_names) == set(operation["confirmed_tags"])
            assert set(result["user_added_labels"]) == set(operation["user_added_labels"])
            
            # Verify by retrieving the document from processed documents
            get_response = requests.get(f"{self.base_url}/documents")
            assert get_response.status_code == 200
            
            # Find our document
            documents = get_response.json()["data"]["documents"]
            retrieved_doc = None
            for doc in documents:
                if doc["document_id"] == document_id:
                    retrieved_doc = doc
                    break
            
            assert retrieved_doc is not None, f"Document {document_id} not found in operation {i+1}"

            # Check new JSONB structure for confirmed_tags
            confirmed_tags = retrieved_doc["confirmed_tags"]
            assert "tags" in confirmed_tags
            retrieved_tag_names = [tag["tag"] for tag in confirmed_tags["tags"]]
            assert set(retrieved_tag_names) == set(operation["confirmed_tags"])
            assert set(retrieved_doc["user_added_labels"]) == set(operation["user_added_labels"])
            
            # Verify AI suggestions are preserved
            assert len(retrieved_doc["suggested_tags"]) == 4
        
        print("  [PASS] Data consistency maintained across all operations")
        print("[SUCCESS] Tag data consistency test completed")

    def check_tag_endpoints_available(self):
        """Check if tag endpoints are available in the running service"""
        try:
            root_response = requests.get(f"{self.base_url}/")
            if root_response.status_code == 200:
                root_data = root_response.json()
                endpoints = root_data.get("data", {}).get("endpoints", [])
                return any("tags" in endpoint for endpoint in endpoints)
        except:
            pass
        return False

def run_all_tag_e2e_tests():
    """Run all tag-related E2E tests"""
    print("="*80)
    print("STARTING END-TO-END TESTS FOR TAG OPERATIONS")
    print("="*80)
    
    test_suite = TestTagOperationsE2E()
    test_suite.setup_method()
    
    # Check if tag endpoints are available
    if not test_suite.check_tag_endpoints_available():
        print("‚ö†Ô∏è  [SKIP] Tag update endpoints not available in running service")
        print("   The service needs to be restarted to pick up the new tag functionality")
        print("   To test tag operations:")
        print("   1. Stop the current service")
        print("   2. Restart with: cd ../.. && python app.py")
        print("   3. Run tag tests again")
        print("")
        print("="*80)
        print("TAG E2E TEST RESULTS: 0 passed, 0 failed (SKIPPED - Service restart needed)")
        print("="*80)
        return True  # Don't fail the test suite, just skip
    
    tests = [
        test_suite.test_tag_update_endpoint_availability,
        test_suite.test_full_tag_management_workflow,
        test_suite.test_concurrent_tag_operations,
        test_suite.test_tag_operations_with_various_data_types,
        test_suite.test_tag_operations_error_scenarios,
        test_suite.test_tag_operations_performance,
        test_suite.test_tag_data_consistency_across_operations,
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            test_suite.setup_method()
            test()
            test_suite.teardown_method()
            passed += 1
        except Exception as e:
            print(f"[FAIL] {test.__name__} failed: {e}")
            failed += 1
            test_suite.teardown_method()
    
    print("="*80)
    print(f"TAG E2E TEST RESULTS: {passed} passed, {failed} failed")
    print("="*80)
    
    return failed == 0

if __name__ == "__main__":
    success = run_all_tag_e2e_tests()
    exit(0 if success else 1)